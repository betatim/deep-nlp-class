{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing text for Machine-learning\n",
    "\n",
    "A long document made up of words is not a good representation for computers.\n",
    "\n",
    "We need to convert the text into a better representation. Here we will look at\n",
    "some baseline methods that work very well in practice. They also form the basis\n",
    "of more complicated ideas used later on. Strong baselines are important in a world\n",
    "of deep learning. You have to be able to demosntrate that the additional complexity,\n",
    "reduced explainability, and additional technical debt from using deep learning is\n",
    "worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"The Uber driver behind the wheel of an autonomous car that hit \"\n",
    "             \"and killed a pedestrian in Arizona could have avoided the collision \"\n",
    "             \"if she had not been distracted, according to police investigating \"\n",
    "             \"the incident.\",\n",
    "             \"An avoidability analysis by police in Tempe, Arizona following March's\"\n",
    "             \" crash suggested that Rafaela Vasquez, Uber's safety driver, may have \"\n",
    "             \"been watching the online video service Hulu in the car.\",\n",
    "             \"The death of 49-year-old Elaine Herzberg is believed to be the first \"\n",
    "             \"time an autonomous car has killed a bystander, prompting a series of \"\n",
    "             \"investigations into what happened.\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bag of words representation of the above sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that you can undo your bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what fraction of entries are not zero in X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X>0).sum(axis=1) / X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ready made tools for this\n",
    "\n",
    "scikit-learn has tools to do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ... use CountVectorizer()\n",
    "\n",
    "print(sorted(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the learnt mapping to convert sentences to bag of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the vector representation back to \"words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a difference between what `CountVectorizer` says how many features\n",
    "# there are and your manual code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify movies from their reviews\n",
    "\n",
    "Fetch the dataset from http://ai.stanford.edu/~amaas/data/sentiment/ and un'tar it to\n",
    "a directory near to this notebook. I placed it in `../data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"../data/aclImdb/train/\", categories=['neg', 'pos'])\n",
    "\n",
    "text_trainval, y_trainval = reviews_train.data, reviews_train.target\n",
    "\n",
    "print(\"type of text_train: {}\".format(type(text_trainval)))\n",
    "print(\"length of text_train: {}\".format(len(text_trainval)))\n",
    "print(\"class balance: {}\".format(np.bincount(y_trainval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"classes: {}\".format(set(y_trainval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at an example review\n",
    "print(\"text_train[42]:\\n{}\".format(text_trainval[42].decode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorise the review texts!\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "text_trainval = [doc.replace(b\"<br />\", b\" \") for doc in text_trainval]\n",
    "\n",
    "# ... your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out some of the words\n",
    "feature_names = vect.get_feature_names()\n",
    "print(feature_names[:10])\n",
    "print(feature_names[30000:30010])\n",
    "print(feature_names[::3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression model to the data and measure the performance\n",
    "# of the model. We now have a baseline we need to improve on.\n",
    "# What score do you achieve on which dataset? Did you split into training\n",
    "# and testing datasets?\n",
    "# \n",
    "# Once you have your model running tune the regularisation strength `C`\n",
    "# using RandomSearchCV or LogisticRegressionCV which is more efficient\n",
    "# Use scikit-learn for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out which words correlate with a good and a bad review.\n",
    "# You can inspect the weights of the linear model by looking\n",
    "# at the coefs_ property of your LogisticRegression instance\n",
    "# Check the documentation to learn about all the properties:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#\n",
    "# do they seem sensible? Could you explain why a review is\n",
    "# getting a high or a low predicted sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "* investigate how to configure the vectorizer to exclude stop words\n",
    "* should you fix the spelling of misspelt words?\n",
    "* only include words that appear more than N times?\n",
    "* only include the M most frequent words?\n",
    "* how few examples do you need to achieve a \"good\" performance?\n",
    "* a bag of words does not know anything about the order of words,\n",
    "  can you construct bi-grams (pairs of words) and improve the\n",
    "  performance?\n",
    "* construct a logistic regression model in keras and use that instead\n",
    "  of using scikit-learn's implementation\n",
    "\n",
    "\n",
    "# Term frequency, inverse document frequency\n",
    "\n",
    "Instead of counting how often a word appears we can also use TfIdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "text_classifier = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3, max_df=0.8, ngram_range=(1, 2)),\n",
    "    LogisticRegression(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text_classifier.fit(text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier.score(text_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline results\n",
    "\n",
    "With about 20s of computer time and a few minutes of work we are at 88% accuracy.\n",
    "\n",
    "We have not really tuned this baseline yet, it is possible that some investment in \n",
    "finding better hyperparamters will improve the baseline further. Try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
