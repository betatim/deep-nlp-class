{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks\n",
    "\n",
    "(This example is based on a lecture from EE-559 â€“ Deep learning by Francois Fleuret,\n",
    "an [excellent resource](https://documents.epfl.ch/users/f/fl/fleuret/www/dlc/).)\n",
    "\n",
    "Why do we need something more complicated than the simple RNN from the slides?\n",
    "\n",
    "This notebook will demosntrate that a simple RNN struggles to learn as quickly as a LSTM.\n",
    "\n",
    "A recurrent model maintains a recurrent state that is updated at each time\n",
    "step. Given a sequence $x$ and an initial recurrent state $h_0$ the model\n",
    "computes a sequence of recurrent states:\n",
    "$$\n",
    "h_t = \\Phi(x_t, h_{t-1}), \\mathsf{with\\ } t = 1, 2, 3, ...\n",
    "$$\n",
    "\n",
    "We will try and solve the problem of deciding if a sequence is a mirror of itself or not\n",
    "using recurrent neural networks.\n",
    "\n",
    "| sequence | label |\n",
    "|----------|-------|\n",
    "| (1,2, 1,2) | 1 |\n",
    "| (3,4, 5,6) | 0 |\n",
    "| (7, 7)     | 1 |\n",
    "| (6,4,2, 6,4,2) | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# define a function that can tell if a sequence x is mirrored\n",
    "# or not\n",
    "def is_mirrored(x):\n",
    "    return np.allclose(x[:x.shape[0]//2], x[-x.shape[0]//2:])\n",
    "\n",
    "\n",
    "def generate_data(n_samples=100, max_length=10):\n",
    "    \"\"\"Generate sequences that are mirrored or not.\n",
    "    \n",
    "    It should return approximately `n_samples` samples\n",
    "    with a roughly equal split between the two classes\n",
    "    \n",
    "    `max_length` sets the maximum length a HALF sequence can\n",
    "    have. For each sequence a length is picked at random\n",
    "    between 1 and `max_length`. This means total length of\n",
    "    the sequence is 2*max_length.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "Generate a dataset with a lot of entries. It is a good idea to get everything\n",
    "running with a small dataset, and then increase it. This way you don't spend\n",
    "too much time waiting for errors that only occur after training.\n",
    "\n",
    "Split your data into a training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, counter = generate_data(30000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25326"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check we get very roughly 30000 samples\n",
    "# I got about 25000 samples when asking for 30k\n",
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20260, 20, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what shape should the data have? Depends on max_length\n",
    "# and how many different symbols there are\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train should be one-hot encoded\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 11358, 0.0: 8902})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the dataset is roughly balanced\n",
    "Counter(y_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you understand what all this does\n",
    "# feel free to experiment with some settings\n",
    "\n",
    "def make_model(lstm=False):\n",
    "    \"\"\"Construct a simple recurrent network.\n",
    "    \n",
    "    Uses either a `SimpleRNN` or a `LSTM` depending\n",
    "    on the value of `lstm`.\n",
    "    \"\"\"\n",
    "    x = Input(shape=X_train.shape[1:])\n",
    "    if lstm:\n",
    "        # ... your code for a LSTM layer here ...\n",
    "        # use the relu activation\n",
    "    else:\n",
    "        # ... your code for a SimpleRNN here ...\n",
    "        # use the relu activation\n",
    "    h = Dense(2)(h)\n",
    "    out = Activation('softmax')(h)\n",
    "    model = Model(inputs=x, outputs=out)\n",
    "    model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = make_model()\n",
    "lstm = make_model(lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that you can correctly predict the rough value of the\n",
    "# accuracy of each of the untrained networks before\n",
    "# getting started. Was your prediction correct?\n",
    "# Score your untrained model to check your guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.47061643, 0.5293836 ],\n",
       "        [0.27798405, 0.722016  ],\n",
       "        [0.37072337, 0.62927663],\n",
       "        [0.5167797 , 0.4832203 ],\n",
       "        [0.4999961 , 0.50000393]], dtype=float32), array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.predict(X_test[:5]), y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both networks for 30 epochs. Check if you should\n",
    "# train them for more or less iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnn_history = rnn.fit(X_train, y_train, epochs=30,\n",
    "                      validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_history = lstm.fit(X_train, y_train, epochs=30,\n",
    "                        validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function that can take a Python\n",
    "# iterable as input and applies each of the model's `predict()`\n",
    "# method to it, printing a human friendly version of the result\n",
    "# Do the models work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the model construction function so that it\n",
    "# can use a GRU layer as well. How does the GRU\n",
    "# compare to the LSTM and Simple RNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with longer sequences.\n",
    "# When do things stop working?\n",
    "# What if you increase or decrease the number of allowed symbols\n",
    "# that can appear in a sequence? Right now it is just integers, how about chars?\n",
    "# How does the accuracy on the test set behave\n",
    "# as a function of sequence length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.9403522e-01, 1.0596478e-01],\n",
       "       [9.6727699e-01, 3.2722980e-02],\n",
       "       [9.1677642e-01, 8.3223537e-02],\n",
       "       [9.9965203e-01, 3.4801522e-04],\n",
       "       [9.9946386e-01, 5.3611689e-04]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5066/5066 [==============================] - 0s 69us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23871791721025665, 0.8969601263324122]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Can you create a dataset of correctly spelt words and words with typos in them?\n",
    "\n",
    "Can your RNNs learn to classify words as typos? What about words they've never seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
