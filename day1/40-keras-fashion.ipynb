{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a two layer NN with keras\n",
    "\n",
    "Implement our two layer neural network using keras!\n",
    "\n",
    "Start with a neural network that jsut does logistic regression. Make sure you can\n",
    "identify all the pieces from `20-logistic-regression.ipynb` in your keras setup.\n",
    "\n",
    "Once you have your keras logistic regression model working extend it to have one hidden layer\n",
    "with dimension 20 (or there abouts). Think about what nonlinearity (or activation function) you want to use.\n",
    "\n",
    "Keras documentation: https://keras.io/models/model/ (note that there are two kinds of keras API. We will try and stick to the \"functional\" API. People seem to prefer that and are moving to it. A matter of taste?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets.mnist import load_data as mnist_data\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "# the first time you execute this it will download the\n",
    "# dataset for you from the internet\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train /255\n",
    "X_test = X_test /255\n",
    "\n",
    "# use a keras builtin utility for the one-hot encoding\n",
    "from keras import utils\n",
    "num_classes = 10\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now using slightly larger images. They are 28x28 pixels large and show clothing items. There are ten classes as in the digits dataset. Feel free to reuse soem code from before to visualise examples from the dataset to get a feeling for what is in it. You can find information about the dataset here: https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the information from the dataset's homepage, what shape\n",
    "# should X_train, X_test, y_train and y_test have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below create a logistic regression \"neural network\" like we have done by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# we define the input shape (i.e., how many input features)\n",
    "# **without** the batch size\n",
    "x = Input(shape=(28*28, ))\n",
    "\n",
    "# all Keras Ops look like z = f(z) (think functional programming)\n",
    "# this is how you'd specify a hidden layer of size 20 using the\n",
    "# relu activation function.\n",
    "#h = Dense(20)(x)\n",
    "#h = Activation('relu')(h)\n",
    "\n",
    "# our outputs are 10 numbers, the probability for each class\n",
    "# you want to apply the Dense layer to the output of a\n",
    "# previous layer often stored in a variable named `h`\n",
    "h = Dense(10)(x)\n",
    "y = Activation('softmax')(h)\n",
    "\n",
    "# Package it all up in a Model\n",
    "net = Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "net.compile(optimizer='sgd',\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "history = net.fit(X_train, y_train, validation_split=0.2,\n",
    "                  epochs=40, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Hyper parameters settings\n",
    "\n",
    "- What will happen to the loss if you run for a very large number\n",
    "  of epochs? What about the validation loss? Can you overfit the training data?\n",
    "- Experiment with different hyper parameters:\n",
    "  - learning rate used by the optimiser,\n",
    "  - change to a different optimiser (ADAM is a good choice),\n",
    "  - size of the hidden layer,\n",
    "  - weight initialization scheme,\n",
    "  - use other activation functions,\n",
    "  - add support for a second, third, n-th hidden layer,\n",
    "  - checkout the `callback` argument to `fit`.\n",
    "- How high can you get your accuracy? (test or train?)\n",
    "- Create an imbalanced dataset where one category has 10x as many samples as the other category. What accuracy can you achieve? Is it impressive?\n",
    "- What happens when you reduce the number of training samples?\n",
    "- Can you train only on the even numbers and then correctly classify the odd number as well as the even numbers?\n",
    "- What happens to the classification accuracy if you add a bit of noise to each image? For example train on clean images and measure performance on noisy images.\n",
    "- How should you decide for how many epochs to train?\n",
    "\n",
    "To find how to change the optimiser and set parameters on it, weight initialisations, and\n",
    "all that make sure to browse the [keras documentation](https://keras.io/models/model/).\n",
    "\n",
    "You can also look at the interactive documentation by writing any Python object you want to see the documentation for in a new notebook cell and placing a question mark after it. For example to learn more about `model.compile` write `model.compile?` in a new cell and run it.\n",
    "\n",
    "Make sure to frequently restart your kernel and run everything from the top. The notebook\n",
    "interface allows you to run cells in any order which is nice for exploration and interactive\n",
    "work but does mean sometimes your kernel ends up in a weird state. \"Restart&run all\" is a best practice when using notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
